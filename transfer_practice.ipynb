{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>ans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>otter\\0.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>otter\\1.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>otter\\10.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>otter\\101.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>otter\\102.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>seal\\95.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>seal\\96.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>seal\\97.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>seal\\98.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>seal\\99.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1058 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               path  ans\n",
       "0       otter\\0.jpg    0\n",
       "1       otter\\1.jpg    0\n",
       "2      otter\\10.jpg    0\n",
       "3     otter\\101.jpg    0\n",
       "4     otter\\102.png    0\n",
       "...             ...  ...\n",
       "1053    seal\\95.jpg    1\n",
       "1054    seal\\96.jpg    1\n",
       "1055    seal\\97.png    1\n",
       "1056    seal\\98.jpg    1\n",
       "1057    seal\\99.jpg    1\n",
       "\n",
       "[1058 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "DIR1 = \"otter\"\n",
    "DIR2 = \"seal\"\n",
    "fs1 = glob.glob(\"{}/*\".format(DIR1))\n",
    "t1 = [0] * len(fs1)\n",
    "fs2 = glob.glob(\"{}/*\".format(DIR2))\n",
    "t2 = [1] * len(fs2)\n",
    "df = pd.DataFrame({\n",
    "    \"path\":fs1 + fs2,\n",
    "    \"ans\":t1 + t2\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "vgg = VGG16(include_top=False, input_shape=(224, 224, 3))\n",
    "vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x2388a8d6e88>,\n",
       " <keras.layers.convolutional.Conv2D at 0x2389e4e47c8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x2389e506248>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x2389e535588>,\n",
       " <keras.layers.convolutional.Conv2D at 0x2389e575108>,\n",
       " <keras.layers.convolutional.Conv2D at 0x2389e558fc8>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x2389e5a69c8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x2389e5c4a48>,\n",
       " <keras.layers.convolutional.Conv2D at 0x2389e5f94c8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x2389e60da88>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x2389e64fc08>,\n",
       " <keras.layers.convolutional.Conv2D at 0x2389e6780c8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x2389e6991c8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x2389e6b3e88>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x2389e6eb808>,\n",
       " <keras.layers.convolutional.Conv2D at 0x2389e6fc808>,\n",
       " <keras.layers.convolutional.Conv2D at 0x2389e71fd48>,\n",
       " <keras.layers.convolutional.Conv2D at 0x2389e74eb48>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x2389e742648>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               6422784   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 21,140,034\n",
      "Trainable params: 6,424,322\n",
      "Non-trainable params: 14,715,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import BatchNormalization\n",
    "# trainable一定要在compile前\n",
    "for l in vgg.layers:\n",
    "    l.trainable = False\n",
    "x = BatchNormalization()(vgg.output)\n",
    "# MLP\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation=\"relu\")(x)\n",
    "x = Dropout(0.25)(x)\n",
    "out = Dense(2, activation=\"softmax\")(x)\n",
    "model = Model(inputs=vgg.input, outputs=out)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ -85.939   ,  -92.779   , -100.68    ],\n",
       "        [ -87.939   ,  -94.779   ,  -94.68    ],\n",
       "        [ -72.939   ,  -76.779   ,  -79.68    ],\n",
       "        ...,\n",
       "        [ -50.939003,  -67.779   ,  -69.68    ],\n",
       "        [ -54.939003,  -70.779   ,  -75.68    ],\n",
       "        [ -62.939003,  -78.779   ,  -83.68    ]],\n",
       "\n",
       "       [[ -79.939   ,  -75.779   ,  -91.68    ],\n",
       "        [ -52.939003,  -49.779   ,  -63.68    ],\n",
       "        [ -53.939003,  -46.779   ,  -65.68    ],\n",
       "        ...,\n",
       "        [ -49.939003,  -66.779   ,  -68.68    ],\n",
       "        [ -53.939003,  -69.779   ,  -74.68    ],\n",
       "        [ -61.939003,  -77.779   ,  -82.68    ]],\n",
       "\n",
       "       [[ -39.939003,  -29.779   ,  -44.68    ],\n",
       "        [ -39.939003,  -30.779   ,  -49.68    ],\n",
       "        [ -31.939003,  -20.779   ,  -45.68    ],\n",
       "        ...,\n",
       "        [ -55.939003,  -69.779   ,  -72.68    ],\n",
       "        [ -52.939003,  -66.779   ,  -71.68    ],\n",
       "        [ -60.939003,  -74.779   ,  -79.68    ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ -54.939003,  -56.779   ,  -73.68    ],\n",
       "        [ -53.939003,  -56.779   ,  -75.68    ],\n",
       "        [ -34.939003,  -37.779   ,  -60.68    ],\n",
       "        ...,\n",
       "        [ -78.939   ,  -93.779   , -108.68    ],\n",
       "        [ -77.939   ,  -94.779   , -106.68    ],\n",
       "        [ -77.939   ,  -97.779   , -107.68    ]],\n",
       "\n",
       "       [[ -54.939003,  -56.779   ,  -71.68    ],\n",
       "        [ -51.939003,  -56.779   ,  -70.68    ],\n",
       "        [ -46.939003,  -51.779   ,  -68.68    ],\n",
       "        ...,\n",
       "        [ -80.939   ,  -95.779   , -110.68    ],\n",
       "        [ -76.939   ,  -93.779   , -105.68    ],\n",
       "        [ -72.939   ,  -92.779   , -102.68    ]],\n",
       "\n",
       "       [[ -43.939003,  -45.779   ,  -60.68    ],\n",
       "        [ -55.939003,  -61.779   ,  -71.68    ],\n",
       "        [ -67.939   ,  -74.779   ,  -86.68    ],\n",
       "        ...,\n",
       "        [ -76.939   ,  -91.779   , -106.68    ],\n",
       "        [ -76.939   ,  -93.779   , -105.68    ],\n",
       "        [ -77.939   ,  -97.779   , -107.68    ]]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://github.com/keras-team/keras-applications/blob/master/keras_applications/imagenet_utils.py\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "p = df.iloc[0][\"path\"]\n",
    "img = load_img(p, target_size=(224, 224)).convert(\"RGB\")\n",
    "img_np = np.array(img)\n",
    "img_pre = preprocess_input(img_np)\n",
    "img_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 5 5 1 0]\n",
      "[81, 25, 25, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "# 試試看numpy的randint\n",
    "ori = np.random.randint(0, 10, 5)\n",
    "new = list(map(lambda x:x**2, ori))\n",
    "print(ori)\n",
    "print(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(path):\n",
    "    img = load_img(path, target_size=(224, 224)).convert(\"RGB\")\n",
    "    img_np = np.array(img)\n",
    "    img_pre = preprocess_input(img_np)\n",
    "    return img_pre\n",
    "\n",
    "def get_images(paths, targets, batch=20):\n",
    "    idx = np.random.randint(0, len(paths), batch)\n",
    "    ps = paths[idx]\n",
    "    xs = np.array(list(map(preprocess, ps)))\n",
    "    ys = targets[idx]\n",
    "    return (ps, xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 1 0 0 1 1 0 1 1 1 0 0 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x = np.array(df[\"path\"])\n",
    "y = np.array(df[\"ans\"])\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y,\n",
    "                                                    test_size=0.1)\n",
    "ps, xs, ys = get_images(x_train, y_train)\n",
    "print(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- Times: 0 ---------------\n",
      "[Train]: [1.2443107, 0.8666667]\n",
      "[Validate]: [4.2239156, 0.9]\n",
      "--------------- Times: 1 ---------------\n",
      "[Train]: [0.392914, 0.95]\n",
      "[Validate]: [2.500846, 0.95]\n",
      "--------------- Times: 2 ---------------\n",
      "[Train]: [1.178179, 0.8]\n",
      "[Validate]: [2.967877, 0.95]\n",
      "--------------- Times: 3 ---------------\n",
      "[Train]: [0.8347114, 0.9]\n",
      "[Validate]: [1.57501, 0.9]\n",
      "--------------- Times: 4 ---------------\n",
      "[Train]: [2.3731706, 0.8]\n",
      "[Validate]: [0.9082445, 0.95]\n",
      "--------------- Times: 5 ---------------\n",
      "[Train]: [0.002342371, 1.0]\n",
      "[Validate]: [0.0115155615, 1.0]\n",
      "--------------- Times: 6 ---------------\n",
      "[Train]: [1.0057646, 0.9]\n",
      "[Validate]: [1.565014, 0.9]\n",
      "--------------- Times: 7 ---------------\n",
      "[Train]: [0.5575205, 0.95]\n",
      "[Validate]: [0.3832127, 0.95]\n",
      "--------------- Times: 8 ---------------\n",
      "[Train]: [0.105720654, 0.95]\n",
      "[Validate]: [0.75797933, 0.9]\n",
      "--------------- Times: 9 ---------------\n",
      "[Train]: [0.24731961, 0.95]\n",
      "[Validate]: [0.46990937, 0.95]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\"-\" * 15, \"Times:\" , i, \"-\" * 15)\n",
    "    _, xs, ys = get_images(x_train, y_train)\n",
    "    train_loss = model.train_on_batch(xs, ys)\n",
    "    print(\"[Train]:\", train_loss)\n",
    "    _, xs, ys = get_images(x_test, y_test)\n",
    "    val_loss = model.test_on_batch(xs, ys)\n",
    "    print(\"[Validate]:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 11s 111ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4896622848510743, 0.9300000071525574]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, xs, ys = get_images(x_test, y_test, 100)\n",
    "model.evaluate(xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.90537441e-33],\n",
       "       [9.62907553e-01, 3.70924100e-02],\n",
       "       [1.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 9.08809575e-17],\n",
       "       [1.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 7.99958760e-18],\n",
       "       [1.00000000e+00, 9.82950602e-23],\n",
       "       [1.00000000e+00, 0.00000000e+00],\n",
       "       [9.99984264e-01, 1.57759277e-05],\n",
       "       [1.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 1.00283271e-11],\n",
       "       [1.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 3.14204788e-22],\n",
       "       [1.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 0.00000000e+00],\n",
       "       [9.07786489e-01, 9.22135189e-02],\n",
       "       [9.99984264e-01, 1.57759277e-05],\n",
       "       [1.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 9.94617257e-15],\n",
       "       [1.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 0.00000000e+00],\n",
       "       [9.21488166e-01, 7.85118863e-02],\n",
       "       [1.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 9.48665249e-37],\n",
       "       [1.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [2.29641326e-15, 1.00000000e+00],\n",
       "       [1.00000000e+00, 0.00000000e+00],\n",
       "       [4.79983839e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 0.00000000e+00],\n",
       "       [9.38414812e-01, 6.15852512e-02],\n",
       "       [1.00000000e+00, 1.96190989e-25],\n",
       "       [1.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 9.83725110e-27],\n",
       "       [3.00865710e-30, 1.00000000e+00],\n",
       "       [1.59216506e-24, 1.00000000e+00],\n",
       "       [1.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 8.17100174e-34],\n",
       "       [2.04680156e-37, 1.00000000e+00],\n",
       "       [4.64836089e-03, 9.95351672e-01],\n",
       "       [1.00000000e+00, 0.00000000e+00],\n",
       "       [9.62907553e-01, 3.70924100e-02],\n",
       "       [3.00865710e-30, 1.00000000e+00],\n",
       "       [1.13897315e-07, 9.99999881e-01],\n",
       "       [1.00000000e+00, 9.82950602e-23],\n",
       "       [9.99997020e-01, 2.98103782e-06],\n",
       "       [1.00000000e+00, 0.00000000e+00],\n",
       "       [1.28429058e-14, 1.00000000e+00],\n",
       "       [3.00865710e-30, 1.00000000e+00],\n",
       "       [3.87539327e-01, 6.12460673e-01],\n",
       "       [1.21589886e-16, 1.00000000e+00],\n",
       "       [4.63397007e-13, 1.00000000e+00],\n",
       "       [1.00000000e+00, 3.14204788e-22],\n",
       "       [1.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [5.15673399e-01, 4.84326631e-01],\n",
       "       [2.76705059e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.96190989e-25],\n",
       "       [5.14525146e-20, 1.00000000e+00],\n",
       "       [1.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 1.11395315e-09],\n",
       "       [1.00000000e+00, 3.56182084e-10],\n",
       "       [1.21589886e-16, 1.00000000e+00],\n",
       "       [1.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 9.48665249e-37],\n",
       "       [1.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 0.00000000e+00],\n",
       "       [9.38414812e-01, 6.15852512e-02],\n",
       "       [1.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 1.90537441e-33],\n",
       "       [1.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 2.91589090e-37],\n",
       "       [1.00000000e+00, 0.00000000e+00],\n",
       "       [9.21488166e-01, 7.85118863e-02],\n",
       "       [1.00000000e+00, 0.00000000e+00],\n",
       "       [1.21589886e-16, 1.00000000e+00],\n",
       "       [1.00000000e+00, 9.48665249e-37],\n",
       "       [1.00000000e+00, 1.90537441e-33],\n",
       "       [1.00000000e+00, 8.17100174e-34],\n",
       "       [1.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 0.00000000e+00],\n",
       "       [1.60125147e-18, 1.00000000e+00],\n",
       "       [1.00000000e+00, 9.48665249e-37],\n",
       "       [1.00000000e+00, 0.00000000e+00],\n",
       "       [9.99984264e-01, 1.57759114e-05],\n",
       "       [2.23658161e-19, 1.00000000e+00],\n",
       "       [1.00000000e+00, 0.00000000e+00],\n",
       "       [7.06301062e-09, 1.00000000e+00],\n",
       "       [8.18306961e-35, 1.00000000e+00],\n",
       "       [1.21589886e-16, 1.00000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 觀察機率: 0.0 1.0絕對有問題\n",
    "model.predict(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 11s 114ms/step\n",
      "命中率: 99.00000095367432 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "ps, xs, ys = get_images(x_test, y_test, 100)\n",
    "accu = model.evaluate(xs, ys)[1]\n",
    "print(\"命中率:\", accu * 100, \"%\")\n",
    "# 如果是使用Model, 而不是Sequential的話\n",
    "# 你會沒有 predict_classes\n",
    "# 你要用predict + argmax來替代\n",
    "pre = model.predict(xs).argmax(axis=1)\n",
    "\n",
    "x_final_test = np.array(list(map(lambda p:np.array(load_img(p)), ps)))\n",
    "idx = np.nonzero(pre != ys)[0][:200]\n",
    "pre_false_img = x_final_test[idx]\n",
    "pre_false_label = ys[idx]\n",
    "pre_false_pre = pre[idx]\n",
    "\n",
    "width = 10\n",
    "height = len(idx) // width + 1\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "trans = [\"Otter\", \"Seal\"]\n",
    "z = zip(pre_false_img, pre_false_label, pre_false_pre)\n",
    "# (i, (z1, z2, z3))\n",
    "for i, (img, label, p) in enumerate(z):\n",
    "    plt.subplot(height, width, i+1)\n",
    "    plt.title(\"[O]:{}\\n[P]:{}\".format(trans[label], trans[p]))\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
